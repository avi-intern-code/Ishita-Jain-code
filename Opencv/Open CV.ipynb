{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//lena.jpg', 0)\n",
    "a.shape\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//lena.jpg', 1)\n",
    "\n",
    "print(a)\n",
    "\n",
    "cv2.imshow('image', a)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))    \n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "print(cap.get(3))\n",
    "print(cap.get(4))\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame', gray)\n",
    "        \n",
    "        if cv2.waitKey(1):\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "a=cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//lena.jpg')\n",
    "\n",
    "print(a.shape)\n",
    "print(a.size)\n",
    "print(a.dtype)\n",
    "b,g,r=cv2.split(a)\n",
    "a=cv2.merge((b,g,r))\n",
    "\n",
    "cv2.imshow('lena_image', a)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "a=cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//messi5.jpg', 1)\n",
    "c=cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//opencv-logo.png', 1)\n",
    "\n",
    "\n",
    "#print(a.shape)\n",
    "#print(b.shape)\n",
    "#print(a.size)\n",
    "#print(a.dtype)\n",
    "#b,g,r=cv2.split(a)\n",
    "#a=cv2.merge((b,g,r))\n",
    "\n",
    "#ball= a[280:340, 330:390]\n",
    "#a[273:333, 100:160] = ball\n",
    "\n",
    "a= cv2.resize(a, (512, 512))\n",
    "c= cv2.resize(b, (512, 512))\n",
    "\n",
    "#dst= cv2.addWeighted (a,-9, c, -1, 0)\n",
    "\n",
    "cv2.imshow('a', a)\n",
    "cv2.imshow('c', c)\n",
    "#cv2.imshow('image', dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a = np.zeros((240, 320, 3), np.uint8)\n",
    "a = cv2.rectangle(a, (200, 0), (300, 100),(255, 255, 255), -1)\n",
    "b = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//LinuxLogo.jpg', 1)\n",
    "\n",
    "#bitAnd = cv2.bitwise_and(a,b)\n",
    "#bitOr = cv2.bitwise_or(a,b)\n",
    "#bitXor = cv2.bitwise_xor(a,b)\n",
    "bitNot1 = cv2.bitwise_not(a)\n",
    "bitNot2 = cv2.bitwise_not(b)\n",
    "\n",
    "cv2.imshow('a', a)\n",
    "cv2.imshow('b', b)\n",
    "#cv2.imshow('bitand', bitAnd)\n",
    "#cv2.imshow('bitor', bitOr)\n",
    "#cv2.imshow('bitxor', bitXor)\n",
    "cv2.imshow('bitnot1', bitNot1)\n",
    "cv2.imshow('bitnot2', bitNot2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "a=cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//download.jpg', 1)\n",
    "#cv2.threshold applies fixed level thresholding to multiple channel array (image, decidig value for hresholding, max value, type)\n",
    "_, th1 = cv2.threshold(a, 127, 255, cv2.THRESH_BINARY) #pixel value less than 127 convert to zero else convert to 1.\n",
    "_, th2 = cv2.threshold(a, 127, 255, cv2.THRESH_BINARY_INV) #more than 127 convert to zero else convert to 1.\n",
    "_, th3 = cv2.threshold(a, 127, 255, cv2.THRESH_TRUNC) # unchanged till 127, after that every pixel convert to 127.\n",
    "_, th4 = cv2.threshold(a, 127, 255, cv2.THRESH_TOZERO) # less than 127 convert to zero else unchanged.\n",
    "_, th5 = cv2.threshold(a, 127, 255, cv2.THRESH_TOZERO_INV) # more than 127 convert to zero else unchanged.\n",
    "\n",
    "\n",
    "#cv2.imshow('th1', th1)\n",
    "#cv2.imshow('th2', th2)\n",
    "#cv2.imshow('th3', th3)\n",
    "#cv2.imshow('th4', th4)\n",
    "cv2.imshow('th5', th5)\n",
    "#plt.imshow(a, cmap='gray')\n",
    "cv2.cvtColor(a, cv2.COLOR_RGB2GRAY)\n",
    "cv2.imshow('image', a)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a=cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//sudoku.png', 0)\n",
    "_, th1 = cv2.threshold(a, 127, 255, cv2.THRESH_BINARY)\n",
    "# adaptive(image,destination image of same size& type, method,threshold type,size of neighbour pixel for calc.threshold,const subtractd from mean)\n",
    "th2 = cv2.adaptiveThreshold(a, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2) \n",
    "# mean_c \n",
    "th3 = cv2.adaptiveThreshold(a, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "cv2.imshow('image', a)\n",
    "cv2.imshow('th1', th1)\n",
    "cv2.imshow('th2', th2)\n",
    "cv2.imshow('th3', th3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//lena.jpg', 1)\n",
    "#a= np.zeros((200, 200), np.uint8)\n",
    "#cv2.rectangle(a, (0, 100), (200, 200), (255), -1)\n",
    "#cv2.rectangle(a, (0, 50), (100, 100), (127), -1)\n",
    "b, g, r = cv2.split(a)\n",
    "hist = cv2.calcHist([a], [0], None, [256], [0, 256])\n",
    "plt.plot(hist)\n",
    "\n",
    "#cv2.imshow('image',a)\n",
    "#cv2.imshow('b',b)\n",
    "#cv2.imshow('g',g)\n",
    "#cv2.imshow('r',r)\n",
    "\n",
    "#plt.hist(a.ravel(), 256, [0, 256])\n",
    "plt.hist(b.ravel(), 256, [0, 256])\n",
    "plt.hist(g.ravel(), 256, [0, 256])\n",
    "plt.hist(r.ravel(), 256, [0, 256])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.ADAPTIVE_THRESH_MEAN_C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "#cap=cv2.VideoCapture(0);\n",
    "cv2.namedWindow(\"tracking\")\n",
    "cv2.createTrackbar('lh', 'tracking', 0, 255, nothing)\n",
    "cv2.createTrackbar('ls', 'tracking', 0, 255, nothing)\n",
    "cv2.createTrackbar('lv', 'tracking', 0, 255, nothing)\n",
    "cv2.createTrackbar('uh', 'tracking', 255, 255, nothing)\n",
    "cv2.createTrackbar('us', 'tracking', 255, 255, nothing)\n",
    "cv2.createTrackbar('uv', 'tracking', 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    frame = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//smarties.png', 1)\n",
    "    #_, frame= cap.read()\n",
    "    \n",
    "    hsv= cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    l_h = cv2.getTrackbarPos('lh', 'tracking')\n",
    "    l_s = cv2.getTrackbarPos('ls', 'tracking')\n",
    "    l_v = cv2.getTrackbarPos('lv', 'tracking')\n",
    "    \n",
    "    u_h = cv2.getTrackbarPos('uh', 'tracking')\n",
    "    u_s = cv2.getTrackbarPos('us', 'tracking')\n",
    "    u_v = cv2.getTrackbarPos('uv', 'tracking')\n",
    "    \n",
    "    l_b = np.array([l_h, l_s, l_v])\n",
    "    u_b = np.array([u_h, u_s, u_v])\n",
    "    mask= cv2.inRange(hsv, l_b, u_b)\n",
    "    \n",
    "    res=cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('res', res)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key==27:\n",
    "        break\n",
    "\n",
    "cap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//halftone.jpg', 1)\n",
    "a= cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "k = np.ones((5, 5), np.float32)/25\n",
    "dst = cv2.filter2D(a, -1, k)\n",
    "blur = cv2.blur(a, (5, 5))\n",
    "gb = cv2.GaussianBlur(a, (5, 5), 0)\n",
    "\n",
    "titles = ['image', '2d', 'blur', 'gb']\n",
    "images = [a, dst, blur, gb]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1), plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]), plt.xticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salt and pepper\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//cam.jpg', 1)\n",
    "a= cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "k = np.ones((5, 5), np.float32)/25\n",
    "dst = cv2.filter2D(a, -1, k)\n",
    "blur = cv2.blur(a, (5, 5))\n",
    "gb = cv2.GaussianBlur(a, (5, 5), 0)\n",
    "median = cv2.medianBlur(a, 5)\n",
    "\n",
    "titles = ['image', '2d', 'blur', 'gb', 'median']\n",
    "images = [a, dst, blur, gb, median]\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]), plt.xticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edges intact\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//lena.jpg', 1)\n",
    "a= cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "k = np.ones((5, 5), np.float32)/25\n",
    "dst = cv2.filter2D(a, -1, k)\n",
    "blur = cv2.blur(a, (5, 5))\n",
    "gb = cv2.GaussianBlur(a, (5, 5), 0)\n",
    "median = cv2.medianBlur(a, 5)\n",
    "bl = cv2.bilateralFilter(a, 9, 75, 75)\n",
    "\n",
    "titles = ['image', '2d', 'blur', 'gb', 'median', 'bl']\n",
    "images = [a, dst, blur, gb, median, bl]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(3, 3, i+1), plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]), plt.xticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//lena.jpg', 1)\n",
    "lr1 = cv2.pyrDown(a)\n",
    "lr2 = cv2.pyrDown(lr1)\n",
    "hr1 = cv2.pyrUp(lr2)\n",
    "\n",
    "cv2.imshow('og', a)\n",
    "cv2.imshow('lr1', lr1)\n",
    "cv2.imshow('lr2', lr2)\n",
    "cv2.imshow('hr1', hr1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#multiple resolution\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//lena.jpg', 1)\n",
    "l = a.copy()\n",
    "gp = [l]\n",
    "\n",
    "for i in range(6):\n",
    "    l = cv2.pyrDown(l)\n",
    "    gp.append(l)\n",
    "    cv2.imshow(str(i), l)\n",
    "\n",
    "cv2.imshow('og', a)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laplacian pyramid\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//lena.jpg', 1)\n",
    "l = a.copy()\n",
    "gp = [l]\n",
    "\n",
    "for i in range(6):\n",
    "    l = cv2.pyrDown(l)\n",
    "    gp.append(l)\n",
    "    #cv2.imshow(str(i), l)\n",
    "    \n",
    "l = gp[5]\n",
    "cv2.imshow('ugp', l)\n",
    "lp = [l]\n",
    "\n",
    "for i in range(5, 0, -1):\n",
    "    ge = cv2.pyrUp(gp[i])\n",
    "    lap = cv2.subtract(gp[i-1], ge)\n",
    "    cv2.imshow(str(i), lap)\n",
    "    \n",
    "cv2.imshow('og', a)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tempelate matching\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//messi5.jpg', 0)\n",
    "t = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//face.png', 0)\n",
    "w, h = t.shape[::-1]\n",
    "\n",
    "res = cv2.matchTemplate(a, t, cv2.TM_CCOEFF_NORMED)\n",
    "print(res)\n",
    "th = 0.9;\n",
    "loc = np.where(res>= th)\n",
    "print()\n",
    "print(loc)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(a, pt, (pt[0] + w, pt[1] + h), (255, 255, 255), 2)\n",
    "\n",
    "cv2.imshow('img', a)\n",
    "cv2.imshow('temp', t)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture('C://Users//Ishita//tutorial//opencv-master//samples//data//vtest.avi')\n",
    "#fg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "#fg = cv2.createBackgroundSubtractorMOG2()  #detect shadows\n",
    "k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "fg = cv2.bgsegm.createBackgroundSubtractorGMG() \n",
    "#fg = cv2.createBackgroundSubtractorKNN() \n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    fgm = fg.apply(frame)\n",
    "    fgm = cv2.morphologyEx(fgm, cv2.MORPH_OPEN, k)\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('fg mask', fgm)\n",
    "    \n",
    "    keyboard = cv2.waitKey(30)\n",
    "    if keyboard == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image gradient\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//sudoku.png', cv2.IMREAD_GRAYSCALE)\n",
    "lap = cv2.Laplacian(a, cv2.CV_64F, ksize=3)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "sobelx = cv2.Sobel(a, cv2.CV_64F, 1, 0)\n",
    "sobely= cv2.Sobel(a, cv2.CV_64F, 0, 1)\n",
    "sobelx= np.uint8(np.absolute(sobelx))\n",
    "sobely= np.uint8(np.absolute(sobely))\n",
    "sobel= cv2.bitwise_or(sobelx, sobely)\n",
    "\n",
    "titles = ('image', 'laplacian', 'sobelx', 'sobely', 'sobel')\n",
    "images = [a, lap, sobelx, sobely, sobel]\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canny edge detector\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//lena.jpg', 0)\n",
    "canny = cv2.Canny(a, 127, 220)\n",
    "\n",
    "titles= ['image', 'canny']\n",
    "img=[a, canny]\n",
    "for i in range(2):\n",
    "     plt.subplot(1, 2, i+1), plt.imshow(img[i], 'gray')\n",
    "     plt.title(titles[i])\n",
    "     plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contour\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//opencv-logo-white.png', 1)\n",
    "ag = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(ag, 127, 255, 0)\n",
    "contour, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "print('no. of countours: '+ str(len(contour)))\n",
    "print(contour[0])\n",
    "\n",
    "cv2.drawContours(a, contour, 0, (0, 255, 0), 3)\n",
    "\n",
    "cv2.imshow('image', a)\n",
    "cv2.imshow('gray', ag)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "a = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//shapes (1).jpg',1)\n",
    "ag = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "_, thresh = cv2.threshold(ag, 240, 255, cv2.THRESH_BINARY)\n",
    "contour, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for contour in contour:\n",
    "    approx = cv2.approxPolyDP(contour, 0.01*cv2.arcLength(contour, True), True)\n",
    "    cv2.drawContours(a, [approx], 0, (0, 0, 0), 5)\n",
    "    x = approx.ravel()[0]\n",
    "    y = approx.ravel()[1]\n",
    "    if len(approx)==3:\n",
    "        cv2.putText(a, 'Triangle', (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "    elif len(approx)==4:\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "        ar = float (w)/h\n",
    "        print(ar)\n",
    "        if ar >= 0.95 and ar<= 1.05:\n",
    "            cv2.putText(a, 'Square', (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "        else:\n",
    "            cv2.putText(a, 'Rectangle', (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "    if len(approx)==5:\n",
    "        cv2.putText(a, 'Pentagon', (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "    else:\n",
    "        cv2.putText(a, 'Circle', (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "cv2.imshow('image', a)\n",
    "cv2.imshow('gray', ag)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shi tomasi corner detector\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "a = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//pic1.png')\n",
    "gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "corners = cv2.goodFeaturesToTrack(gray, 25, 0.01, 10)\n",
    "corners = np.int0(corners)\n",
    "\n",
    "for i in corners:\n",
    "    x, y = i.ravel()\n",
    "    cv2.circle(a, (x, y), 3, 255, -1)\n",
    "    \n",
    "cv2.imshow('image', a)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# harris corner detector\n",
    "import numpy as np\n",
    "import cv2\n",
    "a = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//pic1.png')\n",
    "gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "dst = cv2.dilate(dst, None)\n",
    "a[dst>0.01*dst.max()] = [0, 0, 255]\n",
    "\n",
    "cv2.imshow('image', a)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#morphological transformation\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "a = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//smarties.png', 0)\n",
    "_, mask = cv2.threshold(a, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "kernel = np.ones((2, 2), np.uint8)\n",
    "dilation = cv2.dilate(mask, kernel, iterations=2)\n",
    "erosion = cv2.erode(mask, kernel, iterations=1)\n",
    "opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)   #erosion, dilation\n",
    "closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)  #dilation, erosion\n",
    "mg = cv2.morphologyEx(mask, cv2.MORPH_GRADIENT, kernel)\n",
    "th = cv2.morphologyEx(mask, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "titles = ['image', 'mask', 'dilation', 'erosion', 'opening', 'closing', 'mg', 'th']\n",
    "images = [a, mask, dilation, erosion, opening, closing, mg, th]\n",
    "for i in range(8):\n",
    "     plt.subplot(2, 4, i+1), plt.imshow(images[i], 'gray')\n",
    "     plt.title(titles[i])\n",
    "     plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hough line transform\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//sudoku.png')\n",
    "gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('image', a)\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "cv2.imshow('edges', edges)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n",
    "\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a=np.cos(theta)\n",
    "    b=np.sin(theta)\n",
    "    x0=a*rho\n",
    "    y0=b*rho\n",
    "    x1=int(x0+1000*(-b))\n",
    "    y1=int(y0+1000*(a))\n",
    "    x2=int(x0-1000*(-b))\n",
    "    y2=int(y0-1000*(a))\n",
    "    cv2.line(a, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a= cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//sudoku.png')\n",
    "gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "cv2.imshow('edges', edges)\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2=line[0]\n",
    "    cv2.line(a, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "cv2.imshow('image', a)\n",
    "k=cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hough circle\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//smarties.png')\n",
    "b=a.copy()\n",
    "gray=cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.medianBlur(gray, 5)\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 20, param1=50, param2=30, minRadius=0, maxRadius=0)\n",
    "dct = np.uint16(np.around(circles))\n",
    "for(x, y, r)in dct [0, :]:\n",
    "    cv2.circle(b, (x, y), r, (0, 255, 0), 3)\n",
    "    cv2.circle(b, (x, y), 2,(0, 255, 255), 3)\n",
    "\n",
    "cv2.imshow('b', b)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "net=cv2.dnn.readNet('C://Users//Ishita//tutorial//opencv-master//yolo//yolov3.weights', 'C://Users//Ishita//tutorial//opencv-master//yolo//yolov3.cfg')\n",
    "classes =[]\n",
    "with open('C://Users//Ishita//tutorial//opencv-master//yolo//coco.names.txt', 'r') as f:\n",
    "    classes = f.read().splitlines()\n",
    "    \n",
    "#print(classes)\n",
    "cap = cv2.VideoCapture('C://Users//Ishita//tutorial//opencv-master//samples//data//vtest.avi')\n",
    "#mg = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//messi5.jpg',1)\n",
    "\n",
    "while True:\n",
    "    _,img=cap.read()\n",
    "    height, width,_=img.shape\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416,416), (0,0,0), swapRB=True, crop=False)\n",
    "#for b in blob:\n",
    " #   for n, img_blob in enumerate(b):\n",
    "  #      cv2.imshow(str(n), img_blob)\n",
    "        \n",
    "    net.setInput(blob) # set input from blob into network\n",
    "    output_layers=net.getUnconnectedOutLayersNames() # getting names of output lyers\n",
    "    layersoutputs=net.forward(output_layers) # forwarding names to layersoutputs\n",
    "\n",
    "    boxes=[]\n",
    "    confidences=[]\n",
    "    class_ids=[]\n",
    "\n",
    "    for output in layersoutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id=np.argmax(scores)\n",
    "            confidence=scores[class_id]\n",
    "            if confidence>0.5:\n",
    "                center_x=int(detection[0]*width)\n",
    "                center_y=int(detection[1]*height)\n",
    "                w=int(detection[2]*width)\n",
    "                h=int(detection[3]*height)\n",
    "            \n",
    "                x=int(center_x-w/2)\n",
    "                y=int(center_y-h/2)\n",
    "            \n",
    "                boxes.append([x,y,w,h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "\n",
    "    indexes=cv2.dnn.NMSBoxes(boxes,confidences,0.5,0.4)#0.4 is non max. suppression, 0.5 is confidence\n",
    "\n",
    "\n",
    "    font=cv2.FONT_HERSHEY_PLAIN\n",
    "    colors=np.random.uniform(0,255,size=(len(boxes),3))\n",
    "\n",
    "    for i in indexes.flatten():\n",
    "        x,y,w,h=boxes[i]\n",
    "        label=str(classes[class_ids[i]])\n",
    "        confidence=str(round(confidences[i],2))\n",
    "        color=colors[i]\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(img, label+ \" \" + confidence, (x, y+20), font, 2, (255,255,255), 2)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative image\n",
    "import cv2\n",
    "\n",
    "b = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//LinuxLogo.jpg', 1)\n",
    "\n",
    "bitNot2 = cv2.bitwise_not(b)\n",
    "\n",
    "cv2.imshow('b', b)\n",
    "cv2.imshow('bitnot2', bitNot2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power law (gamma) transformation\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "a=  cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//aero1.jpg', 0)\n",
    "\n",
    "gamma = np.array(255*(a/255)**2.2,dtype='uint8')\n",
    "gamma2 = np.array(255*(a/255)**0.2,dtype='uint8')\n",
    "b = cv2.hconcat([gamma,gamma2])\n",
    "\n",
    "cv2.imshow('a',a)\n",
    "cv2.imshow('b',b)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image addition\n",
    "import cv2\n",
    "\n",
    "src1 = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//src1.jpg');\n",
    "src2 = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//src2.jpg');\n",
    "\n",
    "weightedSum = cv2.addWeighted(src1, 0.5, src2, 0.4, 0)\n",
    "\n",
    "cv2.imshow('src1', src1)\n",
    "cv2.imshow('src2', src2)\n",
    "cv2.imshow('Weighted Image', weightedSum)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image subtraction\n",
    "import cv2 \n",
    "\n",
    "img1 = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//img1.jpg') \n",
    "img2 = cv2.imread('C://Users//Ishita//tutorial//opencv-master//samples//data//img2.jpg')\n",
    "\n",
    "sub = cv2.subtract(img1, img2)\n",
    "  \n",
    "cv2.imshow('img1', img1)\n",
    "cv2.imshow('img2', img2)\n",
    "cv2.imshow('Subtracted Image', sub)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
